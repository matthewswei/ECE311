{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Frequency Response and Sampling\n",
    "## Due Date: 3/20 @ 11:59PM on Canvas\n",
    "\n",
    "This lab will cover the frequency response of LSI systems, the frequency content of digital signals, and sampling basics. We have some interesting applications to get to, so let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete Time Fourier Transform and Frequency Response\n",
    "\n",
    "We will begin with a brief overview of the Discrete Time Fourier Transform (DTFT) and the frequency response of LSI systems.\n",
    "\n",
    "The DTFT is the discrete-time version of our continuous-time Fourier transform (CTFT) from ECE 210. Like the CTFT, the DTFT is a complex-valued function that allows us to examine the frequency content of a signal or system. The DTFT is defined by\n",
    "\n",
    "$$\n",
    "X(\\omega) = \\sum_{n=-\\infty}^{\\infty}x[n]e^{-j\\omega n}\n",
    "$$\n",
    "\n",
    "We also must remember that the DTFT is completely represented by digital frequencies $-\\pi$ to $\\pi$ and is $2\\pi$ periodic. Be careful labeling your frequency axis when taking the DTFT. In Python, we are able to take the DTFT of a signal using numpy's ``fft`` module. The two main functions we will use from this module are $\\textrm{numpy.fft.fft()}$ and $\\textrm{numpy.fft.rfft()}$. The \"fft\" in these functions is the Fast Fourier Transform, which is a computationally efficient way of computing the Discrete Fourier Transform of digital signals. You will learn more about the DFT and FFT in ECE 310 and Lab 5 of this course, but for this lab just think of it as a way of computing the DTFT of a digital signal.\n",
    "\n",
    "Let's look at example usage for these two functions and what makes them different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.ufunc size changed, may indicate binary incompatibility. Expected 232 from C header, got 216 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wavfile\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m imread\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeans\n\u001b[0;32m     11\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\__init__.py:82\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _distributor_init  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __check_build  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[0;32m     85\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    129\u001b[0m ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:17\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_set_output\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _SetOutputMixin\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tags\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     _DEFAULT_TAGS,\n\u001b[0;32m     21\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\__init__.py:19\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmurmurhash\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m murmurhash3_32\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclass_weight\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_class_weight, compute_sample_weight\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _joblib\n",
      "File \u001b[1;32msklearn\\utils\\murmurhash.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.utils.murmurhash\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.ufunc size changed, may indicate binary incompatibility. Expected 232 from C header, got 216 from PyObject"
     ]
    }
   ],
   "source": [
    "# import libraries first\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Audio\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from skimage.io import imread\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0, 1, 0, 2, 0, 2, 0, 1, 0] # test signal\n",
    "\n",
    "full_fft = np.fft.fft(x)\n",
    "real_fft = np.fft.rfft(x)\n",
    "\n",
    "omega_full = np.linspace(0, 2*np.pi, len(full_fft)) # left limit, right limit, # pts\n",
    "omega_real = np.linspace(0, np.pi, len(real_fft))\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.subplot(121)\n",
    "plt.title('Full FFT')\n",
    "plt.xlabel('$\\omega$')\n",
    "plt.ylabel('Magnitude Response')\n",
    "plt.plot(omega_full, np.absolute(full_fft))\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Real FFT')\n",
    "plt.xlabel('$\\omega$')\n",
    "plt.ylabel('Magnitude Response')\n",
    "plt.plot(omega_real,np.absolute(real_fft))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the differences between the $\\textrm{fft()}$ and $\\textrm{rfft()}$ results. The way we have created the frequency axis points may have spoiled the answer, but we see that the $\\textrm{fft()}$ function returns a DTFT with frequencies from 0 to $2\\pi$ while $\\textrm{rfft()}$ just gives us 0 to $\\pi$: the *real* frequencies. It is important to acknowledge when the real frequencies are sufficient. If our signal is real-valued, we know that our spectrum will be Hermitian symmetric. In other words:\n",
    "\n",
    "$$\n",
    "x[n]\\textrm{ real}\\implies X(\\omega) = X^*(-\\omega),\n",
    "$$\n",
    "\n",
    "where $X^*$ refers to the complex conjugate of the DTFT. Why is this important? Well, if our spectrum is Hermitian symmetric, then the spectrum's magnitude response is even symmetric and its phase response is odd symmetric:\n",
    "\n",
    "$$\n",
    "x[n]\\textrm{ real}\\implies |X(\\omega)| = |X(-\\omega)|\\textrm{ and }\\angle X(\\omega) = -\\angle X(-\\omega).\n",
    "$$\n",
    "\n",
    "Thus, if we want to look at the magnitude spectrum of a real-valued signal, it is sufficent to just look at the 0 to $\\pi$ interval since it contains all unique information about the frequency content of our signal.\n",
    "\n",
    "Now, let's make our plots look nicer too. We currently have a couple issues with them. First, they are very low resolution and coarse. Second, the full DTFT example is not zero-centered. Both problems can easily be fixed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0, 1, 0, 2, 0, 2, 0, 1, 0]\n",
    "\n",
    "full_fft = np.fft.fft(x, 512)\n",
    "centered_fft = np.fft.fftshift(full_fft) # shifts central frequency to middle of array\n",
    "real_fft = np.fft.rfft(x, 512)\n",
    "\n",
    "omega_full = np.linspace(-np.pi, np.pi, len(centered_fft)) # new frequency axis\n",
    "omega_real = np.linspace(0, np.pi, len(real_fft))\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.subplot(121)\n",
    "plt.title('Full FFT')\n",
    "plt.xlabel('$\\omega$')\n",
    "plt.ylabel('Real Part')\n",
    "plt.plot(omega_full, np.absolute(centered_fft))\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Real FFT')\n",
    "plt.xlabel('$\\omega$')\n",
    "plt.ylabel('Real Part')\n",
    "plt.plot(omega_real, np.absolute(real_fft))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those plots look so much better now! To fix our first problem with the resolution, we pass a second argument to the $\\textrm{fft()}$ and $\\textrm{rfft()}$ functions to specify the number of points. Do not worry about the underlying math for now, it will be covered later in ECE 310. For now, think of the number of points as dictating how many frequencies we would like to use in capturing the signal's DTFT. Try changing the number of points in the above code and observe the resolution of the DTFT. We fix the second problem by using $\\textrm{np.fft.fftshift()}$ on our full DTFT result. This function zero-centers our DTFT for us along the frequency axis: how convenient!\n",
    "\n",
    "**For the rest of this lab and in the future, it is critical you remember these tips. Always make sure your FFT has a enough points to look clean, and always make sure to appropriately label your frequency axis. Also, for this lab, when we say to \"take the DTFT of a signal\", use the $\\textrm{np.fft.rfft()}$ function unless noted otherwise since we will only work with real signals.**\n",
    "\n",
    "Lastly, let's see how we can look at the frequency response of an LSI system. The function we will use is $\\textrm{signal.freqz()}$, which returns the normalized digital frequencies and frequency response given the numerator and denominator coefficients for an LSI system's transfer function. It is convention to plot a system's frequency response on a dB scale $\\left(20\\cdot\\log_{10}(x)\\right)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [np.sin((np.pi/2)*n)/(0.5*np.pi*n) if n != 0 else 1 for n in range(-100, 101)] # numerator coefficients\n",
    "a = [1,0] #denominator coefficients\n",
    "w, h = signal.freqz(b, a) # w = omega/digital frequencies, h = frequency response\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Toy Frequency Response')\n",
    "plt.plot(w, 20*np.log10(np.absolute(h))) # plot magnitude of frequency response with db-scaling on y-axis\n",
    "plt.xlabel('$\\omega$')\n",
    "plt.ylabel('Magnitude Response (dB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Implementing the DTFT\n",
    "\n",
    "We will begin by implementing the DTFT according to the above definition for an arbitrary collection of frequencies. We will test using signals over a finite support, so we will modify our definition of the DTFT to simply say\n",
    "\n",
    "$$\n",
    "X(\\omega) = \\sum_{n=0}^{N-1}x[n]e^{-j\\omega n}.\n",
    "$$\n",
    "\n",
    "a. Implement the $\\textrm{myDTFT()}$ function below, which returns the DTFT values for a given list of digital frequencies.\n",
    "\n",
    "b. Use your DTFT function to compute the DTFT of $x[n] = \\cos(\\frac{\\pi}{2}n)$, $0\\leq n < 50$ for 50 evenly spaced frequencies from $-\\pi$ to $\\pi$ (non-inclusive). Also, compute the DTFT of $x[n]$ using $\\textrm{np.fft.fft()}$. Plot the magnitude and phase of the two implementations in separate figures to verify you achieve the same result. Use $\\textrm{np.absolute()}$ and $\\textrm{np.angle()}$ for the magnitude and phase responses, respectively. Don't forget to zero-center the frequency axis of the $\\textrm{np.fft.fft()}$ result using $\\textrm{np.fft.fftshift()}$.\n",
    "\n",
    "c. Theoretically, the DTFT of $\\cos(\\omega_0n)$ should give us Kronecker deltas at $\\pm\\omega_0$. However, we see our implementation and the numpy DTFT function result in some non-ideal representation, like in the ramping behavior around the frequencies of the cosine. Why does this happen? Hint: consider how our practical definition of the DTFT in this exercise differse from the theoretical definition of the DTFT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to implement for part 1.a:\n",
    "\"\"\"\n",
    "Inputs:\n",
    "x - input signal (list or np.array)\n",
    "w - frequencies we want to compute the DTFT for (list or np.array)\n",
    "Output:\n",
    "dtft - value of the DTFT for signal x at each frequency specified in w (list or np.array)\n",
    "\"\"\"\n",
    "def myDTFT(x, w):\n",
    "    dtft = [] # create empty list to append resulting computation\n",
    "    # Iterate over each frequency in w\n",
    "    \n",
    "    # Compute summation for current frequency according to our DTFT definition, \"1j\" gives you the imaginary number\n",
    "    \n",
    "    # Append result for current frequency\n",
    "    \n",
    "    return dtft\n",
    "\n",
    "# Code for part 1.b:\n",
    "x = np.array([np.cos(0.5*np.pi*n) for n in range(50)])\n",
    "# endpoint argument makes sure our definition aligns with the np.fft.fft result\n",
    "w = np.linspace(-np.pi, np.pi, 50, endpoint=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments here\n",
    "\n",
    "Part 1(c):\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Toy LSI Signals and Systems\n",
    "\n",
    "For this exercise, we will get some practice with inspecting the DTFT of digital signals and frequency response of LSI systems. For parts 2.a and 2.b, plot the resulting magnitude and phase of the DTFT of each signal. Please place the two plots for each signal side-by-side using $\\textrm{plt.subplot()}$. Don't forget to specify a larger number of points in your DTFT like 512. For parts 1.c and 1.d, plot the magnitude response of each system as shown above using $\\textrm{signal.freqz()}$ use a dB scaling on the y-axis.\n",
    "\n",
    "$\\begin{align}\n",
    "a. x_1[n] = \\frac{1}{4}\\delta[n]+\\frac{1}{2}\\delta[n-1] + \\delta[n-2] + \\frac{1}{2}\\delta[n-3] + \\frac{1}{4}\\delta[n-4]\n",
    "\\end{align}$\n",
    "\n",
    "$\\begin{align}\n",
    "b. x_2[n] = -\\delta[n] + 2\\delta[n-2] - \\delta[n-4]\n",
    "\\end{align}$\n",
    "\n",
    "$\\begin{align}\n",
    "c. H_3(z) = \\frac{z^2 -2z + 1}{z^2 -\\frac{1}{2}z + \\frac{1}{4}}\n",
    "\\end{align}$\n",
    "\n",
    "$\\begin{align}\n",
    "d. H_4(z) = \\frac{z^4 + 2z^3 + z^2}{z^4-\\frac{1}{2}z^3+\\frac{1}{4}z^2-\\frac{1}{8}z + \\frac{1}{16}}\n",
    "\\end{align}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for 2.a:\n",
    "# Remember to plot magnitude and phase of signals side-by-side with plt.subplot(nrows,ncols,plot number)\n",
    "\n",
    "\n",
    "# Code for 2.b:\n",
    "\n",
    "\n",
    "# Code for 2.c:\n",
    "# Remember to plot magnitude response with dB-scaling on y-axis.\n",
    "\n",
    "# Code for 2.d:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sinusoidal Response of LSI Systems\n",
    "\n",
    "We recall from ECE 210 that the response of LTI systems to sinusoidal inputs has a nice closed form using the frequency response of our system. The same is true for our discretized LSI systems! Let $H(\\omega)$ be our frequency response and our input be some sinusoidal input with arbitrary amplitude $A$, frequency $\\omega_0$, and phase $\\theta$:\n",
    "\n",
    "$$\n",
    "A\\sin(\\omega_0n + \\theta) \\to \\begin{bmatrix}H(\\omega)\\end{bmatrix} \\to A|H(\\omega_0)|sin(\\omega_0n + \\theta + \\angle H(\\omega_0))\n",
    "$$\n",
    "\n",
    "We see that the output is simply the input signal scaled by the magnitude response and we add phase according the value of the phase response at the sinusoid's frequency. Furthermore, we can extend this notion to sums of sinusoids by the linearity of our LSI systems. Now, let's verify this with an example system!\n",
    "\n",
    "# Exercise 3: Sinusoidal Response of an LSI System\n",
    "\n",
    "For all parts of this problem, we will consider the following LSI system:\n",
    "\n",
    "$$\n",
    "h[n] = \\frac{1}{2}\\delta[n] + \\delta[n-2] + \\frac{1}{2}\\delta[n-4]\n",
    "$$\n",
    "\n",
    "a. Plot the magnitude and phase response of the above system. Do not use a dB-scale when plotting this system. Use 512 for the number of points in your DTFT. Verify your results by computing the frequency response by hand.\n",
    "\n",
    "Consider the following two inputs:\n",
    "\n",
    "$\\begin{align}\n",
    "\\bullet~x_b[n] = 1 + 2\\sin\\left(\\frac{\\pi}{4}n\\right), \\quad 0\\leq n < 100\n",
    "\\end{align}$\n",
    "\n",
    "$\\begin{align}\n",
    "\\bullet~x_c[n] = 2 + 10\\sin\\left(\\frac{\\pi}{2}n\\right) + 4\\cos\\left(\\pi n\\right), \\quad 0\\leq n < 100\n",
    "\\end{align}$\n",
    "\n",
    "b. Apply the filter $h[n]$ to input $x_b[n]$ using $\\textrm{signal.lfilter()}$. Plot the magnitude of the DTFT for the input and filtered output, respectively, on separate subplots. Use 512 points again for your DTFT. Verify these results by hand!\n",
    "\n",
    "c. Apply the filter $h[n]$ to input $x_c[n]$. Plot the magnitude of the DTFT for the input and filtered output, respectively, on separate subplots. Also verify these results by hand!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for part 3.a:\n",
    "\n",
    "\n",
    "# Code for part 3.b:\n",
    "\n",
    "\n",
    "# Code for part 3.c:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Yanny or Laurel? Why not both?\n",
    "\n",
    "For this next exercise, we will visualize the effects of applying LSI systems as filters by looking in the frequency domain. But let's work with something more interesting than toy systems or signals: the infamous \"Yanny or Laurel?\" audio clip we used in Lab 1. Some people hear Yanny while others hear Laurel. In this activity, we will show using signal processing that both are audible and hopefully shed some light on this auditory illusion.\n",
    "\n",
    "We have provided two filters in the files ``filter-one.npy`` and ``filter-two.npy`` in addition to the audio clip. Do not worry about the design of these filters. We will cover filter design in more detail in Lab 6. \n",
    "\n",
    "a. Use $\\textrm{np.load()}$ to load each filter. Note that these coefficients are simply the numerator coefficients of the transfer functions. We will assume a denominator of 1. Plot the magnitude of the DTFT for the audio signal using $\\textrm{np.fft.rfft()}$ and the frequency response for each filter using $\\textrm{signal.freqz()}$.\n",
    "\n",
    "b. Apply each filter to the audio clip using $\\textrm{signal.lfilter()}$. Listen to the results from each filter. **As always, be careful with your volume before listening**.\n",
    "\n",
    "c. What sounds different in each filtered audio clip? Does this explain the auditory illusion? If so, how? If you are having trouble hearing a difference, try changing the playback sampling frequency for the filtered results a little ($\\pm$10-20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs, audio = wavfile.read('audiofile.wav') # load the data\n",
    "print(audio.shape) # one channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=audio, rate=fs) # give it a listen for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for 4.a\n",
    "\n",
    "\n",
    "# Code for 4.b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to typecast audio before listening to it as follows:\n",
    "audio_result1 = audio_result1.astype(np.int16)\n",
    "audio_result2 = audio_result2.astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listen to result 1 here!\n",
    "Audio(data=audio_result1, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to result 2 here!\n",
    "Audio(data=audio_result2, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments here:\n",
    "\n",
    "Part 4(c):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling and Analog-to-Digital Conversion\n",
    "\n",
    "For the second half of this lab, we will focus on the process of sampling and storing digital signals. We will begin with some review.\n",
    "\n",
    "When sampling a continuous time signal, we must be careful to sample at an appropriate frequency. For any bandlimited signal with a maximum frequency of $f_{max}$ or bandwidth $B$, we can guarantee no aliasing if we sample above twice $f_{max}$. This is known as the Nyquist criterion:\n",
    "\n",
    "$$\n",
    "f_s > 2B = f_{Nyquist}.\n",
    "$$\n",
    "\n",
    "How can we relate the analog and digital frequencies before and after sampling? There is a simple equation for that!\n",
    "\n",
    "$$\n",
    "\\omega_d = \\Omega_aT,\n",
    "$$\n",
    "\n",
    "where $T$ is the sampling period, $\\omega_d$ is our digital frequency, and $\\Omega_a$ is the analog frequency. Recall that the DTFT of a digital signal is $2\\pi$ periodic and our digital frequencies are bounded between $-\\pi$ and $\\pi$. For example, suppose we have a signal $x(t)$ with $f_{max}$ = 35kHz and we sample at $f_s = 30kHz$. Where will this maximum frequency lie in the digital spectrum?\n",
    "\n",
    "$$\n",
    "\\omega_d = 2\\pi\\cdot35000\\cdot\\frac{1}{30000}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\omega_d = \\frac{7\\pi}{3}\n",
    "$$\n",
    "\n",
    "Clearly, we have sampled below the Nyquist rate, and thus the signal has aliased. The max frequency directly maps to $\\frac{7\\pi}{3}$; however, by the $2\\pi$ periodicity of the DTFT, we will also have a frequency component at $\\frac{7\\pi}{3}-2\\pi = \\frac{\\pi}{3}$ in the central copy of the DTFT. Excercise 5 will give you some practice with different sampling rates and how to explain aliasing.\n",
    "\n",
    "In ECE 310, we mainly focus on the sampling part of the analog-to-digital conversion process. Don't forget that in practice we must consider quantization effects. We cannot store every possible analog value of a signal, so we must select a finite number of levels to represent our data. Most simply in ECE 110, we learn about uniform quantizers where the levels are evenly spaced throughout the dynamic range (range of possible values). Each captured sample is \"rounded\" or quantized to its nearest level. But we should also consider other quantization schemes. For example, what if most of our analog samples densely range between 0V-1V, while a few noisy samples spike up to 5V. A uniform quantizer would lose resolution at lower voltages and accomodate the noisy samples too much. Perhaps there is a better way? Excercise 6 will show you an example of a non-uniform quantizer and let you compare it with a uniform quantizer on a couple test images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5: It's a bird! It's a plane! No, it's just aliasing!\n",
    "\n",
    "We will now get some hands-on experience with aliasing and sampling effects. Python has a helpful function in the ``scipy.signal`` package called $\\textrm{signal.chirp()}$ that generates a swept cosine signal. This means we can create a sweeping tone between a start and end frequency. Unfortunately, the documentation for this function is a bit confusing, so let's briefly demonstrate its usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 44100 # sampling rate for audio clip in Hz\n",
    "t1 = 5 # make clips 5 seconds\n",
    "t = np.linspace(0, t1, t1*Fs) # make sure to specify the number of points to match desired sampling frequency!!!\n",
    "f0 = 0 # start frequency (Hz)\n",
    "f1 = 22050 # end frequency (Hz)\n",
    "\n",
    "\"\"\"\n",
    "instantanous frequency, f(t) = f0 + (f1-f0)*(t/t1)\n",
    "\"\"\"\n",
    "\n",
    "chirp_original = signal.chirp(t, f0=f0, t1=t1, f1=f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BE CAREFUL WITH YOUR VOLUME! CHIRP SEQUENCES CAN BE LOUD!\n",
    "\n",
    "Audio(data=chirp_original, rate=Fs) # give it a listen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now inspect the signals we create and try changing the sampling rate.  Once again, be careful when listening to audio.\n",
    "\n",
    "a. Plot the magnitude of the DTFT of the ``chirp_original`` signal. Plot your frequency axis in digital frequency (0 to $\\pi$). What is the maximum frequency our sound card can represent for the sampling frequency used to generate this signal?\n",
    "\n",
    "b. Generate a second chirp with a sampling frequency of 29,400. Assume the same $t_1$, $f_0$, and $f_1$ from above. Listen to the resulting audio and plot the magnitude of the DTFT for this chirp. Explain what you hear (why do you hear what you hear) and relate it to your DTFT plot. Remember to share the same sampling frequency between generating the time sequence and your soundcard like in the above example.\n",
    "\n",
    "c. Suppose we wanted to hear three complete rises and two complete falls in the generated chirp. What sampling frequency should we specify when generating the audio chirp to achieve this strange goal? Briefly explain how you arrived at your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for 5.a here:\n",
    "\n",
    "\n",
    "# Code for 5.b here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code cell to listen to different chirps you generate\n",
    "Audio(data=current_chirp, rate=current_fs) # Remember to use correct sampling frequency!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments here\n",
    "\n",
    "Part 5(a):\n",
    "    \n",
    "\n",
    "Part 5(b):\n",
    "\n",
    "\n",
    "Part 5(c):\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6: Which Crayons Should You Use?\n",
    "\n",
    "You are a new hire at Crayola; the crayons division, to be specific. Your title is \"Swiss-Army Knife of Signal Processing\", or at least that's what your business cards say. Your team is working on a new problem from customer feedback. Parents are sick of buying huge crayon packs where their kids don't use all the colors. It's a waste! There is a new initiative to deliver coloring packs to consumers where they get a coloring book and a select group of crayons that include all the colors they will need to create their masterpieces. So, the question is: how do we best pick the colors in the crayon pack?\n",
    "\n",
    "Your predecessor came up with a naive solution where you simply create a uniform quantizer with evenly spaced levels for the desired number of colors. However, there are a couple problems with this:\n",
    "\n",
    "* This solution only works for grayscale pictures.\n",
    "* It works poorly for very bright or dark images. We don't use all the colors!\n",
    "\n",
    "Before you improve on this system, let's first implement it ourself as a baseline for comparison. Note, for the following three parts, you may play around with the value of $k$. Try values in the range of 2-16. Before turning your lab in, you may fix $k$ to be 4 for each part.\n",
    "\n",
    "a. Fill in the below function $\\textrm{uniform_quantizer()}$ that implements this uniform color quantizer. Test your function on the ``grayscale-test.jpg`` image. Plot the original and quantized images side-by-side.\n",
    "\n",
    "Now, you know a great fix to make sure all the crayons are used and the colored-in image looks close to the original one. You are going to use Lloyd-max quantization, which is commonly referred to as k-means clustering! Do not worry too much about the math of k-means clustering, the quantization function is provided for you below and your answers for the last part may be qualitative. **Note: The code to perform Lloyd-max quantization may take a minute or two to run.**\n",
    "\n",
    "b. Test the $\\textrm{lm_quantizer()}$ function on the ``grayscale-test.jpg`` image and plot the original and quantized images side-by-side.\n",
    "\n",
    "Another advantage of Lloyd-Max quantization/k-means clustering is that it extends easily to multiple dimensions, like color images. In fact, we can use the same function for both types of images!\n",
    "\n",
    "c. Test the $\\textrm{lm_quantizer()}$ function on the ``color-test.jpg`` image and plot the original and quantized images side-by-side.\n",
    "\n",
    "d. Compare the results from the uniform and Lloyd-Max quantizers. How does the Lloyd-Max quantizer appear to work differently? You may explain your observations qualitatively or quantitatively. If you need help explaining, you can read up on k-means <a href=\"https://en.wikipedia.org/wiki/K-means_clustering\">here</a> or <a href=\"http://scikit-learn.org/stable/modules/clustering.html#k-means\">there</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 6.a\n",
    "# Fill in the below function!\n",
    "\"\"\"\n",
    "image - image we want to color quantize\n",
    "k - number of quantization levels (# of crayons)\n",
    "For example, k = 4 means we will have levels at 0, 85, 170, and 255.\n",
    "\n",
    "returns: q_image = color quantized image\n",
    "\"\"\"\n",
    "def uniform_quantizer(image, k):\n",
    "    # create quantization levels\n",
    "    levels = np.linspace(0, 255, k) # k evenly spaced colors from 0 (black) to 255 (white)\n",
    "    # create a new/blank version of the image and compute quantization level spacing\n",
    "    q_image = np.zeros(image.shape)\n",
    "    spacing = 255/(k-1)\n",
    "    # go through each pixel in the original image, assign quantized value to new/blank image\n",
    "    # remember we choose the quantization level closest to the original value\n",
    "    \n",
    "    # return your quantized image\n",
    "    return q_image\n",
    "\n",
    "\n",
    "# Part 6.b/6.c\n",
    "# Function has been provided for you!\n",
    "\"\"\"\n",
    "image - image we want to color quantize\n",
    "k - number of quantization levels\n",
    "\n",
    "returns: q_image = color quantized image\n",
    "\"\"\"\n",
    "def lm_quantizer(image, k):\n",
    "    im_shape = image.shape\n",
    "    n_rows = im_shape[0]\n",
    "    n_cols = im_shape[1]\n",
    "    # create k-means object\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    # reshape pixel value to be like data points\n",
    "    if len(im_shape) == 2:\n",
    "        pixel_vals = np.array([[image[row, col]] for row in range(n_rows) for col in range(n_cols)])\n",
    "    else:\n",
    "        pixel_vals = np.array([image[row, col] for row in range(n_rows) for col in range(n_cols)])\n",
    "    # fit the k-means model to pixel data and get color labels\n",
    "    color_labels = kmeans.fit_predict(pixel_vals)\n",
    "    # create blank version of the image\n",
    "    q_image = np.zeros(im_shape).astype(np.uint8)\n",
    "    # assign appropriate color to each pixel based on color labels\n",
    "    colors = kmeans.cluster_centers_.astype(np.uint8)\n",
    "    for i,label in enumerate(color_labels):\n",
    "        q_image[int(i/n_cols), i % n_cols] = colors[label]\n",
    "    return q_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to test 6.a\n",
    "\n",
    "\n",
    "# Code to test 6.b\n",
    "\n",
    "\n",
    "# Code to test 6.c\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments here\n",
    "\n",
    "Part 6(d):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Instructions\n",
    "\n",
    "Please rename this notebook to \"netid_Lab4\" and submit a zip file including all the supplied files for this lab to Canvas. Please also name your zip file submission \"netid_Lab4\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
