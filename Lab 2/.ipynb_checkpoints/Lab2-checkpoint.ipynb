{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE 311 Lab 2: LSI Systems\n",
    "## Due Date: 2/13 @ 11:59PM on Canvas\n",
    "In this lab, we will explore Linear Shift-Invariant (LSI) systems and their properties with applications involving toy signals, image filtering, stock data, and even an example of a simple non-linear system. Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries for this lab\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.io import imread\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started with Convolution\n",
    "\n",
    "We remember from ECE 210, that convolution describes how any continuous-time input signal is processed by an LTI system. Given an input $x(t)$ and an LTI system's impulse response $h(t)$, the system output $y(t)$ is given by\n",
    "\n",
    "$$\n",
    "y(t) = x(t) * h(t).\n",
    "$$\n",
    "\n",
    "Recall that convolution for continous-time signals is defined as\n",
    "\n",
    "$$\n",
    "y(t) = \\int_{\\tau = -\\infty}^{\\infty}x(\\tau)h(t-\\tau)d\\tau = \\int_{\\tau=-\\infty}^{\\infty}x(t-\\tau)h(\\tau)d\\tau.\n",
    "$$\n",
    "\n",
    "You have learned in ECE 310 that discrete-time LTI systems also have an impulse response $h[n]$, which is the system response to a unit Kronecker delta $\\delta[n]$ input. Thus, we can express the system output given an input signal via discrete-time convolution.\n",
    "\n",
    "$$\n",
    "y[n] = x[n] * h[n]\n",
    "$$\n",
    "\n",
    "$$\n",
    "y[n] = \\sum_{k=-\\infty}^{\\infty}x[k]h[n-k] = \\sum_{k=-\\infty}^{\\infty}x[n-k]h[k]\n",
    "$$\n",
    "\n",
    "Like the width properties of continuous-time convolution, if $x$ is of length $N$ and $h$ is of length $M$, the result $y$ will be of length $N+M-1$. It is important to note that every LTI system can be represented by a convolution, every system that can be expressed as a convolution is fully described by its impulse response, and any system fully described by its impulse response must be LTI. This means the relationship between LTI systems, convolution, and impulse responses is an \"if and only if\" relationship; they all imply one another! This is something handy to keep in mind whenever you want to identify and describe an LTI system.\n",
    "\n",
    "The key function we will use to perform convolutions is the $\\textrm{convolve()}$ function in the $\\textrm{scipy.signal}$ module. The usage of this function for an example system is as follows:\n",
    "\n",
    "$$\n",
    "x[n] = \\delta[n]+2\\delta[n-2]+3\\delta[n-4]\n",
    "$$\n",
    "\n",
    "$$\n",
    "y[n] = x[n]+3x[n-1]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 2 6 3 9]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 0, 2, 0, 3]) # input signal\n",
    "h = np.array([1, 3]) # filter/system's impulse response\n",
    "y = signal.convolve(x,h) # signal.convolve(in1,in2)\n",
    "\n",
    "print(y) # verify this result by hand!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we extracted the system's impulse response for the system's Linear Constant Coefficient Difference Equation (LCCDE): we simply replace each $x[n-k]$ with $\\delta[n-k]$! This is equivalent to passing $\\delta[n]$ as our input signal. Above, our first term takes the present input value and multiplies it by one, and the second term multiplies the most recent input by three. Intuitively, when we flip and shift our filter $h$ for the convolution, we will be applying this system to the input signal at each shift step. The $\\textrm{signal.convolve()}$ function assumes the arrays that represent our signals begin at index zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Implementing LTI Systems\n",
    "\n",
    "In the below code cell, implement the following LTI systems and plot the system response (using $\\textrm{plt.stem()}$) to each of the listed input signals. Comment on the results in the following Markdown cell, i.e. compare and contrast how each system seems to affect each input signal. Remember to use the LCCDE for each system to infer its impulse response!\n",
    "\n",
    "* System A: $y_a[n] = x[n]-x[n-1]$\n",
    "\n",
    "\n",
    "* System B: $y_b[n] = \\frac{1}{3}x[n]+\\frac{1}{3}x[n-1]+\\frac{1}{3}x[n-2]$\n",
    "\n",
    "\n",
    "\n",
    "* $x_1[n] = u[n] - u[n-10], 0\\leq n< 20$\n",
    "\n",
    "\n",
    "* $x_2[n] = \\sin\\left(\\frac{\\pi}{20}n\\right), 0\\leq n< 40$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create input signals here:\n",
    "# Hint: Use np.sin and np.pi!\n",
    "\n",
    "# System A\n",
    "\n",
    "# plot result for x1\n",
    "\n",
    "# plot result for x2\n",
    "\n",
    "\n",
    "# System B\n",
    "\n",
    "# plot result for x1\n",
    "\n",
    "# plot result for x2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments here:\n",
    "\n",
    "(Consider how each system affects the flatter and faster-changing parts of the input signals. What do you think each system is doing?)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Bitcoin Pricing Correction\n",
    "\n",
    "One type of signal could be some non-physical 1D information. An example of this would be stock price or cryptocurrency price data. This data is notoriously noisy and can jump around unpredictably.\n",
    "\n",
    "Remember that the systems we work with can be either causal or non-causal. A causal system only uses present and past information or values to calculate its present values, while a non-causal system can leverage future information. In this exercise, we will compare causal and non-causal versions of a system to smooth a day's worth of bitcoin price data. We have provided 24 hours of prices with pricing updates every minute (1440 points). The date in question is Christmas Eve Day (12/24), 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_data = np.load('bitcoin-christmas.npy', allow_pickle=True)\n",
    "n_points = len(bitcoin_data)\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.plot(range(n_points), bitcoin_data)\n",
    "plt.title('Bitcoin Prices Every Minute 12/24/2017')\n",
    "plt.xlabel('Minute from Midnight')\n",
    "plt.ylabel('Price (USD)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty noisy, right? Maybe a lot of last-minute Christmas gifts made the price even more unpredictable!\n",
    "\n",
    "In this exercise, you will implement two length-51 moving average filters on this Bitcoin price data. The first will be causal and the second will be non-causal. Mathematically, we can represent these systems as follows:\n",
    "\n",
    "$$\n",
    "y_1[n] = \\frac{1}{51}\\sum_{i=0}^{50}x[n - i]\n",
    "$$\n",
    "\n",
    "$$\n",
    "y_2[n] = \\frac{1}{51}\\sum_{i=-25}^{25}x[n - i]\n",
    "$$\n",
    "\n",
    "Furthermore, since the moving average filter is an LTI system we may implement it as a convolution using its impulse response. If you are having trouble seeing this, we suggest considering a length-5 moving average filter and \"unrolling\" the sum to understand that system definition and its impulse response.\n",
    "\n",
    "Notice that the non-causal filter will require us to access negative indices according to the impulse response of our filter. A natural question to ask is how does the $\\textrm{signal.convolve()}$ function perform non-causal convolution? How can you indicate negative indices when making an array for a system's impulse response? This is where the \"same\" mode comes in! We may use the \"same\" mode as follows:\n",
    "\n",
    "```\n",
    "y = signal.convolve(x, h, 'same'),\n",
    "```\n",
    "\n",
    "where $x$ is of length $N$ and $h$ is length $M$. This line of code will first perform regular convolution like the default mode where the first sample of each sequence is assumed to be at $n=0$. Then, it will only keep the center $N$ values (length of first argument/array). This operation is equivalent to zero-centering the second argument/array (```h``` in the above example). You may want to try a couple small examples to convince yourself this is true. The \"same\" mode will be important to keep in mind throughout this lab and the rest of the course.\n",
    "\n",
    "**Important Note:** For the following two parts, we have provided the appropriate start and end indices to help us make sure each implementation returns results of the same size and to remove initial condition worries (ramping behavior since we would have fewer than 51 samples as the filter has partial overlap). **Please follow the plotting instructions in the following parts carefully!**\n",
    "\n",
    "a. Construct the causal filter and apply it to the provided bitcoin price data (apply your causal system to the data in the ``bitcoin_data`` variable). To make sure your output is the same length and matches up correctly in time, please slice the result of convolving ``bitcoin_data`` with your causal filter using ``start`` and ``end``. Note that we do this to create the ``plotting_data`` variable. Plot the original data (``plotting_data``) and your smoothed data on the same plot. **Don't forget to include a legend!**\n",
    "\n",
    "b. Construct the non-causal filter and apply it to the provided bitcoin price data (``bitcoin_data`` variable). Perform the same ``start`` and ``end`` slicing on your result as in part (a). Plot the original data (``plotting_data``) and your smoothed data on the same plot.\n",
    "\n",
    "c. Plot the difference signals for each filter on the same plot. Let the difference signal for a system's output be given by\n",
    "\n",
    "$$\n",
    "y_d = y - \\hat{y},\n",
    "$$\n",
    "\n",
    "where $\\hat{y}$ is your system output and $y$ is the sliced original data used for plotting, ``plotting_data``.\n",
    "\n",
    "d. Comment on the results in the following Markdown cell. What is noticeably different between the two sets of smoothed results from the causal and non-causal systems? Is it helpful to know a lot of past information or a decent amount of past and future information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided code\n",
    "L = 51\n",
    "half_L = 25\n",
    "start = 50\n",
    "end = len(bitcoin_data)-half_L\n",
    "plotting_data = bitcoin_data[start:end] # plot against this data in parts a/b, pay attention to how we slice\n",
    "result_length = len(plotting_data)\n",
    "\n",
    "# Code for 2.a here, don't forget to plot original and filtered signals on same plot!\n",
    "\n",
    "\n",
    "# Code for 2.b here\n",
    "        \n",
    "    \n",
    "# Code for 2.c here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments for here:\n",
    "\n",
    "Part 2(d):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ECE 310, we typically focus on the implications of applying LTI systems in the frequency domain of a 1D signal. Our most common idea of a 1D signal is a piece of audio. In this section, we will experiment with image filtering along both axes of an image and see that we can do more than just filtering with convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: 1D Image Convolution\n",
    "\n",
    "Apply a 1D length 11 moving average filter on the provided ``test-image.jpg`` image along the:\n",
    "\n",
    "**Note: we will use the 'same' mode again when using $\\textrm{signal.convolve()}$ for this exercise.**\n",
    "\n",
    "a. Rows \n",
    "\n",
    "b. Columns\n",
    "\n",
    "c. Rows then columns (**Hint**: make sure to convolve first along the rows, then use the result of this row-convolution to convolve along the columns!)\n",
    "\n",
    "d. Columns then rows (**Hint**: make sure to convolve first along the columns, then use the result of this column-convolution to convolve along the rows!)\n",
    "\n",
    "Plot each of the resulting images and give them unique titles.\n",
    "\n",
    "e. Comment on the images from the \"rows then columns\" and \"columns then rows\" procedures. Are they the same? Explain your answer, why are they the same or different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make filter and load image\n",
    "image = imread('test-image.jpg')\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('Original Image')\n",
    "L = 11\n",
    "h = np.ones(L) * 1/11 # impulse response of length-11 moving average filter\n",
    "n_rows, n_cols = image.shape\n",
    "# Code for 3.a along rows (apply filter to each row independently)\n",
    "image_row = np.zeros(image.shape)\n",
    "# Hint: image_row[i, :] = signal.convolve(image[i, :], h, 'same') for each row\n",
    "\n",
    "# along the columns (3.b)\n",
    "\n",
    "# rows then columns (3.c)\n",
    "\n",
    "# columns then rows (3.d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments here\n",
    "\n",
    "Part 3(e):\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Building an Edge Detector\n",
    "\n",
    "Let's now apply image convolution to perform edge detection. We will build a simple edge detector step-by-step using the following simple 1D filter:\n",
    "\n",
    "$$\n",
    "h[n] = \\delta[n] - \\delta[n-1]\n",
    "$$\n",
    "\n",
    "a. Intuitively or mathematically, what does this filter do to an input signal? In other words, what parts of a signal would give a strong (large magnitude) response and what parts would give a weak (small magnitude) response? You may answer this with a couple signal examples and the result of convolution with $h[n]$ or qualitative intuition.\n",
    "\n",
    "b. Is this filter causal? Why or why not? In general, is it a problem if an image filter is non-causal? (Hint: consider the contexts in which we can or cannot violate causality.)\n",
    "\n",
    "**Note**: For the next two parts, please store your results in separate variables. This will make part (e) much cleaner.\n",
    "\n",
    "c. Apply $h[n]$ along the rows of the ``test-image.jpg`` image. Plot the result with a grayscale color mapping.\n",
    "\n",
    "d. Apply $h[n]$ along the columns of the ``test-image.jpg`` image. Plot the result with a grascale color mapping.\n",
    "\n",
    "So far we have checked for edge-like features in the image going along the rows and columns. Imagine these two results as indicating edge strength along the row axis (vertical edges) and column axis (horizontal edges) of the image, respectively. Take a minute to look at the differences between these two resulting images. Can you tell which one is detecting edges within a row and which one is doing so within a column? What would be a sensible way to incorporate these two dimensions of information? Imagine they form a 2D vector and take the norm! More precisely:\n",
    "\n",
    "$$\n",
    "I_F(r,c) = \\sqrt{\\left(I_R(r,c)\\right)^2 + \\left(I_C(r,c)\\right)^2},\n",
    "$$\n",
    "\n",
    "where $I_R$ and $I_C$ are the row and column filtered results from parts (c) and (d) above, respectively.\n",
    "\n",
    "e. Build the final result image $I_F$ according to the above equation. Plot the result again with a grayscale color mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments here\n",
    "\n",
    "Part 4(a):\n",
    "\n",
    "\n",
    "Part 4(b):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test-image.jpg\n",
    "test = imread('test-image.jpg')\n",
    "\n",
    "# Code for 4.c here:\n",
    "\n",
    "\n",
    "# Code for 4.d here:\n",
    "\n",
    "\n",
    "# Code for 4.e here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Image Convolution\n",
    "\n",
    "We don't need to limit ourselves to 1D image convolution. Our filters or \"kernels\" can be in two dimensions also! We will not spend much time on the math of 2D convolution/filtering in this class because it is best left for ECE 418 (Image and Video Processing); still,  we can use Python to try it out. But let's try something other than filtering this time!\n",
    "\n",
    "Image convolution is not just for filtering or modifying an image. We can also use convolution to extract information from an image. Remember that convolution is is the process of \"flipping and shifting\" one signal over another signal. At each shift location, we perform a dot product (or inner product) to see how $\\textit{similar}$ the signals are. A larger magnitude value at the output means the two signals are more similar. The following image illustrates 2D convolution.\n",
    "\n",
    "<img src=\"convolution.jpg\">\n",
    "\n",
    "More formally, say we have a $3x3$ convolution kernel $\\mathcal{K}$ where the center pixel is at index $(0,0)$, the result of the 2D convolution at pixel $(i,j)$ for image $I$, $O(i,j)$ is given by:\n",
    "\n",
    "$$\n",
    "O(i,j) = \\sum_{k=-1}^{1}\\sum_{l=-1}^{1}\\mathcal{K}(k,l)I(i-k,j-l)\n",
    "$$\n",
    "\n",
    "Now, why is this useful? Suppose you want to design a system to recognize handwritten digits. How can you tell the difference between a \"1\" and a \"4\", for example? Think about how you as a human can separate these numbers! They both typically have one large vertical line down the middle, but we know we can differentiate them because a \"4\" has another shorter vertical line (depending how you draw it) and a horizontal line connecting them. This is where 2D convolution can help us! How about we create convolution kernels to highlight features we know to be discriminative, like horizontal and vertical lines.\n",
    "\n",
    "The below code cell includes a function to perform 2D image convolution on a target image given a convolution kernel. We have also provided two 2D kernels: one for horizontal features and another for vertical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_2d(image, kernel):\n",
    "    result = signal.convolve2d(image, kernel, 'same')\n",
    "    result[result < 0] = 0 # Keep values non-negative\n",
    "    return result\n",
    "\n",
    "# identify horizontal lines\n",
    "horiz_kernel = np.array([[-2,-2,-2,-2,-2],\n",
    "                         [1,1,1,1,1],\n",
    "                         [1,1,1,1,1],\n",
    "                         [1,1,1,1,1],\n",
    "                         [-2,-2,-2,-2,-2]])\n",
    "\n",
    "# identify vertical lines\n",
    "vert_kernel = np.array([[-2,1,1,1,-2],\n",
    "                        [-2,1,1,1,-2],\n",
    "                        [-2,1,1,1,-2],\n",
    "                        [-2,1,1,1,-2],\n",
    "                        [-2,1,1,1,-2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the folder for this lab, we have provided example images of the numbers \"1\", \"4\", and \"8\" from the popular MNIST dataset. These images are 28x28 and grayscale. Let's see what our filters can identify in the ``one.jpg`` image! Note the different scales on the feature image colorbars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = imread('one.jpg')\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.subplot(131)\n",
    "plt.title('Original')\n",
    "plt.imshow(one, 'gray')\n",
    "\n",
    "one_horiz = convolve_2d(one, horiz_kernel)\n",
    "plt.subplot(132)\n",
    "plt.title('Horizontal Features')\n",
    "plt.imshow(one_horiz, 'hot')\n",
    "plt.colorbar(fraction=0.05)\n",
    "\n",
    "one_vert = convolve_2d(one, vert_kernel)\n",
    "plt.subplot(133)\n",
    "plt.title('Vertical Features')\n",
    "plt.imshow(one_vert, 'hot')\n",
    "plt.colorbar(fraction=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5: 2D Image Convolution for Feature Detection\n",
    "\n",
    "a. Create similar plots as the above example for the \"1\" image for the \"4\" (``four.jpg``) and \"8\" (``eight.jpg``) images in the following code cell.\n",
    "\n",
    "b. Comment on the results and compare what is highlighted for each number.\n",
    "\n",
    "c. What is the significance of having negative kernel values around the positive \"feature highlighting\" values? Think about what would happen if the negative values were zeros instead. Try playing around with the kernels or creating your own kernel if you are unsure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for 5.a here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments here:\n",
    "\n",
    "Part 5(b):\n",
    "\n",
    "Part 5(c):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final activity, we will explore an example of a non-linear system. First, a bit of background.\n",
    "\n",
    "There are many different types of noise that can appear in images. One such type is salt-and-pepper noise. This noise occurs when pixels in a camera or an existing image become fully active or inactive. In other words, a normal pixel either takes on its minimum or maximum possible value. The following code cell shows an original image and a version of it that has been corrupted by 20% salt-and-pepper noise (20% of the pixels are affected). In this activity, we will see whether we can use our LTI systems from before to denoise our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_image = imread('clean-image.jpg')\n",
    "noisy_image = imread('noisy-image.jpg')\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(121)\n",
    "plt.imshow(clean_image, 'gray')\n",
    "plt.title('Original Image')\n",
    "plt.subplot(122)\n",
    "plt.imshow(noisy_image, 'gray')\n",
    "plt.title('Image with 20% Salt-and-Pepper Noise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6: Non-Linear Systems are Cool Too!\n",
    "\n",
    "We will attempt to use two different filters: a 5x5 mean filter and a 5x5 median filter. Note that a median filter is a non-linear system! A 5x5 median filter simply takes the median of the 25 pixels surrounding the center pixel in the filter and assigns that value to the center pixel.\n",
    "\n",
    "a. Explain/prove why the median filter is a non-linear system. If you don't know where to start, try showing a counter-example for how a one-dimensional median filter fails the test for linearity. \n",
    "\n",
    "b. Apply a 5x5 mean filter to the noisy image and plot the result. You can do this two different ways. You can apply a length-5 mean filter along the rows and columns in any order or use our $\\textrm{convolve_2d()}$ function from before with an appropriate filter you create.\n",
    "\n",
    "c. Apply a 5x5 median filter to the noisy image and plot the result. Use $\\textrm{signal.medfilt()}$ to perform the filtering. Look up the scipy documentation for notes on this function's usage.\n",
    "\n",
    "d. Comment on the differences. Which filter seems to work better? Why do you think so?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for 6.b\n",
    "\n",
    "\n",
    "# Code for 6.c\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments here\n",
    "\n",
    "Part 6(a):\n",
    "\n",
    "Part 6(d):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Instructions\n",
    "\n",
    "Make sure to place all image and data files along with your .ipynb lab report (this file) in one folder, zip the folder, and submit it to Canvas under the Lab 2 assignment. Please name the zip file ``<netid>_Lab2``."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
